{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unexpected-casino",
   "metadata": {},
   "source": [
    "# EAs Goodreads Analysis\n",
    "### Questions:\n",
    "- ~~what are most popular books~~\n",
    "- ~~what are most to-read but not read books~~\n",
    "- ~~highest/lowest rated~~\n",
    "- average books read per year\n",
    "- books that many people read before EA was a thing\n",
    "- ~~books that are relatively fringe but read by EAs~~\n",
    "- express the numbers as percentages, too\n",
    "\n",
    "### ToDo:\n",
    "- it looks like for a few profiles, e.g. \"117194676\" and \"52226471\" my program didn't return the books even though their profiles are public\n",
    "    - I might have messed up something when I split up the scraping into multiple sessions\n",
    "\n",
    "### Scraping ethics\n",
    "- as far as I can see, all pages I scrape are not disallowed: https://www.goodreads.com/robots.txt\n",
    "    - (weirdly there seem to be ~200 books that are individually not allowed to be scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dynamic-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "import lxml\n",
    "import pandas as pd\n",
    "import random\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "silent-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.goodreads.com/group/151274-effective-altruists/members'\n",
    "#response = requests.get(url)\n",
    "#response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "earned-rating",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-cooperative",
   "metadata": {},
   "source": [
    "### Get all user sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "infinite-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "for i in range(1,14):\n",
    "    time.sleep(random.uniform(16,34))\n",
    "    response = requests.get(url + \"?page=\" + str(i))\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    all_tags = soup.findAll(\"a\", attrs={\"class\": \"userName\"})\n",
    "    all_refs = []\n",
    "    for tag in all_tags:\n",
    "        all_refs.append(tag.get(\"href\"))\n",
    "    users = users + all_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "neutral-doctor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cleared-match",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/user/show/68316850-gavin</td>\n",
       "      <td>68316850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/user/show/54920478-karolina</td>\n",
       "      <td>54920478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/user/show/25104703-jola-cora</td>\n",
       "      <td>25104703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/user/show/79393925-yannick-m</td>\n",
       "      <td>79393925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/user/show/96107289-scott-constantine</td>\n",
       "      <td>96107289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     URL        ID\n",
       "0              /user/show/68316850-gavin  68316850\n",
       "1           /user/show/54920478-karolina  54920478\n",
       "2          /user/show/25104703-jola-cora  25104703\n",
       "3          /user/show/79393925-yannick-m  79393925\n",
       "4  /user/show/96107289-scott-constantine  96107289"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_users = pd.DataFrame(users, columns=[\"URL\"])\n",
    "#df_users[\"ID\"] = df_users[\"URL\"].str.replace(r\"\\D\", '', regex=True)\n",
    "#df_users.to_csv(\"GoodreadsEAs.csv\")\n",
    "#df_users = pd.read_csv(\"GoodreadsEAs.csv\")\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-leave",
   "metadata": {},
   "source": [
    "### Get books\n",
    "#### Plan\n",
    "- go through each EA one by one\n",
    "- go through their books\n",
    "- save\n",
    "    - read or not\n",
    "    - if rated: rating\n",
    "    - if read: (first) date it was read\n",
    "- data structure:\n",
    "    - one df for each user\n",
    "    - one row for each book\n",
    "    - columns for read/to-read, rating, date\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-kinase",
   "metadata": {},
   "source": [
    "#### How to navigate along the page\n",
    "- Format of list of books: https://www.goodreads.com/review/list/{userID}\n",
    "- Master list doesn't have reading status info, seems like I have to go seperately through \"read\", \"currently reading\" and \"to read\"\n",
    "    - ?shelf=read\n",
    "    - ?shelf=currently-reading\n",
    "    - ?shelf=to-read\n",
    "- &page={i}\n",
    "    - starting with 1\n",
    "    - ends with \"No books matching\"\n",
    "- &per_page=100\n",
    "    - Goodreads gives me 30 books per page no matter what, weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "central-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_books(soup, userID, shelf):\n",
    "    \"\"\"Gets soup of whole page, returns df with books of that page.\"\"\"\n",
    "    all_books = soup.findAll(\"tr\", attrs={\"class\": \"bookalike review\"})\n",
    "    \n",
    "    titles = []\n",
    "    alt_titles = []\n",
    "    authors = []\n",
    "    avg_ratings = []\n",
    "    num_reviews_list = []\n",
    "    ratings = []\n",
    "    dates_added = []\n",
    "    dates_read = []\n",
    "    \n",
    "    \n",
    "    for book in all_books:\n",
    "        title = book.findAll(\"td\", attrs={\"class\": \"field title\"})[0].findAll(\"a\")[0].string\n",
    "        titles.append(title)\n",
    "\n",
    "        alt_title = book.findAll(\"td\", attrs={\"class\": \"field title\"})[0].findAll(\"a\")[0][\"title\"]\n",
    "        alt_titles.append(alt_title)\n",
    "\n",
    "        author = book.findAll(\"td\", attrs={\"class\": \"field author\"})[0].findAll(\"a\")[0].string\n",
    "        authors.append(author)\n",
    "\n",
    "        avg_rating = book.findAll(\"td\", attrs={\"class\": \"avg_rating\"})[0].findAll(\"div\")[0].string\n",
    "        avg_rating = float(avg_rating)\n",
    "        avg_ratings.append(avg_rating)\n",
    "\n",
    "        num_reviews = book.findAll(\"td\", attrs={\"class\": \"field num_ratings\"})[0].findAll(\"div\")[0].string\n",
    "        num_reviews = int(num_reviews.replace(\",\", \"\"))\n",
    "        num_reviews_list.append(num_reviews)\n",
    "\n",
    "        # rating - catching unrated books\n",
    "        try:\n",
    "            rating = book\\\n",
    "                    .findAll(\"td\", attrs={\"class\": \"field rating\"})[0]\\\n",
    "                    .findAll(\"span\", attrs={\"class\": \"staticStars notranslate\"})[0][\"title\"]\n",
    "        except KeyError:\n",
    "            rating = None\n",
    "        ratings.append(rating)\n",
    "\n",
    "        # date added - catching undated books\n",
    "        date_added = book.findAll(\"td\", attrs={\"class\": \"field date_added\"})[0].findAll(\"span\")[0].string\n",
    "        try:\n",
    "            date_added = parser.parse(date_added)\n",
    "        except:\n",
    "            date_added = \"not set\"\n",
    "        dates_added.append(date_added)\n",
    "\n",
    "        # date read - catching unread books\n",
    "        date_read = book.findAll(\"td\", attrs={\"class\": \"field date_read\"})[0].findAll(\"span\")[0].string\n",
    "        try:\n",
    "            date_read = parser.parse(date_read)\n",
    "        except:\n",
    "            date_read = \"not set\"\n",
    "        dates_read.append(date_read)\n",
    "\n",
    "        \n",
    "    # these all should be the same length\n",
    "    assert len(titles) == len(alt_titles) == len(authors) == len(avg_ratings) == len(num_reviews_list) == len(ratings) == len(dates_added) == len(dates_read)\n",
    "    \n",
    "    d = {\"userID\": [userID]*len(titles), \"shelf\": [shelf]*len(titles), \"title\": titles, \"alt_title\": alt_titles, \"author\": authors, \"avg_rating\": avg_ratings, \"num_reviews\": num_reviews_list,\n",
    "        \"rating\": ratings, \"date_added\": dates_added, \"date_read\": dates_read}\n",
    "    \n",
    "    return pd.DataFrame(d)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "posted-puppy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>shelf</th>\n",
       "      <th>title</th>\n",
       "      <th>alt_title</th>\n",
       "      <th>author</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>date_added</th>\n",
       "      <th>date_read</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test ID</td>\n",
       "      <td>to-test</td>\n",
       "      <td>Test Title</td>\n",
       "      <td>Test alt. Title</td>\n",
       "      <td>Test Author</td>\n",
       "      <td>3.33</td>\n",
       "      <td>69</td>\n",
       "      <td>liked it</td>\n",
       "      <td>March 3rd, 1933</td>\n",
       "      <td>May 4th, 1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userID    shelf       title        alt_title       author avg_rating  \\\n",
       "0  Test ID  to-test  Test Title  Test alt. Title  Test Author       3.33   \n",
       "\n",
       "  num_reviews    rating       date_added      date_read  \n",
       "0          69  liked it  March 3rd, 1933  May 4th, 1999  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"userID\": [\"Test ID\"], \"shelf\": \"to-test\", \"title\": [\"Test Title\"], \"alt_title\": [\"Test alt. Title\"], \"author\": [\"Test Author\"], \"avg_rating\": [\"3.33\"], \"num_reviews\": [\"69\"],\n",
    "        \"rating\": [\"liked it\"], \"date_added\": [\"March 3rd, 1933\"], \"date_read\": [\"May 4th, 1999\"]}\n",
    "df_books = pd.DataFrame(d)\n",
    "df_books\n",
    "#df_books = pd.read_csv(\"GoodreadsEAs_books.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-forwarding",
   "metadata": {},
   "source": [
    "### Go through all users\n",
    "This got a little messy because Goodreads now and then bounced me so I split up the userIDs in multiple lists.\n",
    "to_scrape should just be list(set(df_users[\"ID\"])) if one wants to start this again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "thorough-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_scrape = list(set(df_users[\"ID\"])^set(df_books[\"userID\"].unique()))\n",
    "#test = pd.Series(to_scrape)\n",
    "#test.to_csv(\"to_scrape.csv\")\n",
    "#to_scrape = read_csv(\"to_scrape.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "streaming-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_scrape1 = to_scrape[0:60]\n",
    "#to_scrape2 = to_scrape[60:120]\n",
    "#to_scrape3 = to_scrape[120:180]\n",
    "#to_scrape4 = to_scrape[180:240]\n",
    "#to_scrape5 = to_scrape[240:300]\n",
    "#to_scrape6 = to_scrape[300:]\n",
    "#missing = [\"68316850\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "retired-silence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some of the accounts that came up empty were actually not hidden. Try again all accounts that I didn't scrape before:\n",
    "all_accounts = set(list(pd.read_csv(\"GoodreadsEAs.csv\")[\"ID\"]))\n",
    "all_scraped_accounts = list(pd.read_csv(\"books.csv\")[\"userID\"])\n",
    "all_scraped_accounts.remove(\"Test ID\")\n",
    "all_scraped_accounts = set([int(i) for i in all_scraped_accounts])\n",
    "missing_accounts = all_accounts - all_scraped_accounts\n",
    "len(missing_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "outside-blink",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 31670283\n",
      "1-1-1-\n",
      " 60292639\n",
      "1-2-3-1-1-2-3-4-5-6-7-8-9-\n",
      " 18885684\n",
      "1-1-1-\n",
      " 65566773\n",
      "1-1-1-\n",
      " 85675576\n",
      "1-1-1-\n",
      " 45366841\n",
      "1-1-1-\n",
      " 108283452\n",
      "1-1-1-\n",
      " 92761167\n",
      "1-1-1-\n",
      " 4756057\n",
      "1-1-1-\n",
      " 6671961\n",
      "1-1-1-\n",
      " 117193318\n",
      "1-1-1-\n",
      " 14350960\n",
      "1-1-1-\n",
      " 49642104\n",
      "1-1-1-\n",
      " 14134912\n",
      "1-1-1-\n",
      " 42826370\n",
      "1-1-1-\n",
      " 80516\n",
      "1-1-1-\n",
      " 45523078\n",
      "1-2-3-4-5-6-7-1-2-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-\n",
      " 27953287\n",
      "1-2-3-4-5-6-1-1-\n",
      " 37354120\n",
      "1-2-3-4-5-6-1-1-\n",
      " 28620424\n",
      "1-1-1-\n",
      " 21839511\n",
      "1-1-1-\n",
      " 56182937\n",
      "1-1-1-\n",
      " 31383725\n",
      "1-2-3-4-5-6-7-8-9-10-1-1-\n",
      " 120963250\n",
      "1-1-1-\n",
      " 37294782\n",
      "1-1-1-\n",
      " 103847111\n",
      "1-1-1-\n",
      " 41208014\n",
      "1-2-3-4-5-6-7-8-9-10-11-12-13-1-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-\n",
      " 84216527\n",
      "1-1-1-\n",
      " 89414359\n",
      "1-1-1-\n",
      " 38695642\n",
      "1-2-3-4-5-6-7-8-9-10-11-12-1-1-2-3-4-5-6-\n",
      " 66766044\n",
      "1-2-3-4-5-6-1-2-1-2-3-4-5-6-7-8-9-10-11-\n",
      " 57238238\n",
      "1-1-1-\n",
      " 85957352\n",
      "1-2-3-4-5-1-2-1-2-3-4-5-6-7-8-\n",
      " 8083189\n",
      "1-2-3-4-5-6-7-1-1-2-3-4-5-6-7-8-9-10-11-12-\n",
      " 22205687\n",
      "1-2-3-1-2-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-\n",
      " 11548927\n",
      "1-1-1-\n",
      " 71816965\n",
      "1-2-1-1-2-\n",
      " 39900938\n",
      "1-1-1-\n",
      " 35936532\n",
      "1-1-1-\n",
      " 8008984\n",
      "1-1-1-\n",
      " 35122458\n",
      "1-1-1-\n",
      " 14875421\n",
      "1-1-1-\n",
      " 90919201\n",
      "1-2-3-4-1-1-2-3-4-5-6-\n",
      " 9835304\n",
      "1-1-1-\n",
      " 117116202\n",
      "1-1-1-\n",
      " 46469931\n",
      "1-1-1-\n",
      " 51233580\n",
      "1-1-1-\n",
      " 39296821\n",
      "1-1-1-\n",
      " 26648902\n",
      "1-1-1-\n",
      " 8817993\n",
      "1-1-1-\n",
      " 51371341\n",
      "1-1-1-\n",
      " 101484878\n",
      "1-1-1-\n",
      " 22055764\n",
      "1-1-1-\n",
      " 58023771\n",
      "1-1-1-\n",
      " 77149020\n",
      "1-1-1-\n",
      " 63327077\n",
      "1-1-1-\n",
      " 44734317\n",
      "1-1-1-\n",
      " 19749237\n",
      "1-1-1-\n",
      " 32697213\n",
      "1-1-1-\n",
      " 101175167\n",
      "1-1-1-\n",
      " 385784194\n",
      "1-1-1-\n",
      " 44645765\n",
      "1-1-1-\n",
      " 4891018\n",
      "1-1-1-\n",
      " 124437386\n",
      "1-1-1-\n",
      " 7671690\n",
      "1-1-1-\n",
      " 10384788\n",
      "1-1-1-\n",
      " 62444952\n",
      "1-2-3-4-5-6-7-1-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-\n",
      " 45340060\n",
      "1-1-1-\n",
      " 55420316\n",
      "1-1-1-\n",
      " 12295590\n",
      "1-1-1-\n",
      " 10968999\n",
      "1-1-1-\n",
      " 12278696\n",
      "1-1-1-\n",
      " 8513966\n",
      "1-2-3-4-1-1-2-3-4-5-6-7-8-9-10-\n",
      " 92096951\n",
      "1-2-3-4-5-6-1-2-1-2-3-4-5-6-7-\n",
      " 29228984\n",
      "1-1-1-\n",
      " 106407868\n",
      "1-1-1-\n",
      " 5346762\n",
      "1-1-1-\n",
      " 97688014\n",
      "1-1-1-\n",
      " 76660175\n",
      "1-2-3-4-1-1-2-3-4-5-6-\n",
      " 77407184\n",
      "1-1-1-\n",
      " 262099\n",
      "1-1-1-\n",
      " 42804189\n",
      "1-1-1-\n",
      " 45821917\n",
      "1-1-1-\n",
      " 5583842\n",
      "1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37-38-39-1-2-3-4-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37-\n",
      " 39901667\n",
      "1-1-1-\n",
      " 44143076\n",
      "1-1-1-\n",
      " 23430627\n",
      "1-1-1-\n",
      " 131857383\n",
      "1-1-1-2-\n",
      " 34999787\n",
      "1-1-1-\n",
      " 30459883\n",
      "1-1-1-\n",
      " 55377392\n",
      "1-1-1-\n",
      " 76173296\n",
      "1-1-1-\n",
      " 52648434\n",
      "1-1-1-"
     ]
    }
   ],
   "source": [
    "base = \"https://www.goodreads.com/review/list/\"\n",
    "for userID in missing_accounts:\n",
    "    print(\"\\n\", userID)\n",
    "    userURL = base + str(userID)\n",
    "    for shelf in [\"read\", \"currently-reading\", \"to-read\"]:\n",
    "        shelfURL = userURL + \"?shelf=\" + shelf\n",
    "        for page in range(1, 200): # don't want to do a while-loop, the super bookworms require ~150 loops\n",
    "            print(page, end=\"-\")\n",
    "            pageURL = shelfURL + \"&page=\" + str(page)\n",
    "            # pageURL += \"&per_page=100\" # for some reason Goodreads returns 30 per page no matter what I call\n",
    "            \n",
    "            time.sleep(random.uniform(22,32))\n",
    "            \n",
    "            response = requests.get(pageURL)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            extracted = extract_books(soup, userID, shelf)\n",
    "            df_books = df_books.append(extracted)\n",
    "            \n",
    "            if extracted.shape[0] < 5:\n",
    "                break\n",
    "    df_books.to_csv(\"booksupdated.csv\")\n",
    "    time.sleep(random.uniform(12,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-front",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
